{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXTicgh5dC6z6mxsPif6f+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viktoriia-kama/ML_hw4-hw16/blob/main/HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2_ULC-LWVy3L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def linear_regression_hypothesis(theta, x):\n",
        "    \"\"\"\n",
        "    Гіпотеза лінійної регресії.\n",
        "\n",
        "    Параметри:\n",
        "    theta (numpy.ndarray): Вектор параметрів розмірності (n+1, 1), де n - кількість ознак,\n",
        "                           theta[0] - зсув (вільний член), theta[1:] - ваги ознак.\n",
        "    x (numpy.ndarray): Вектор ознак розмірності (n+1, 1), включаючи x[0] = 1 для врахування зсуву.\n",
        "\n",
        "    Повертає:\n",
        "    float: Прогнозоване значення за гіпотезою лінійної регресії.\n",
        "    \"\"\"\n",
        "    return np.dot(theta, x)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(theta, X, y):\n",
        "    \"\"\"\n",
        "    Обчислення функції втрат для лінійної регресії.\n",
        "\n",
        "    Параметри:\n",
        "    theta (numpy.ndarray): Вектор параметрів розмірності (n+1, 1), де n - кількість ознак,\n",
        "                           theta[0] - зсув (вільний член), theta[1:] - ваги ознак.\n",
        "    X (numpy.ndarray): Матриця ознак розмірності (m, n+1), де m - кількість зразків,\n",
        "                       n - кількість ознак, X[:,0] містить всі значення зсуву (вільного члена).\n",
        "    y (numpy.ndarray): Вектор цільових значень розмірності (m, 1).\n",
        "\n",
        "    Повертає:\n",
        "    float: Значення функції втрат для заданих параметрів.\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    # Обчислюємо прогнозовані значення за гіпотезою лінійної регресії\n",
        "    predictions = np.dot(X, theta)\n",
        "    # Обчислюємо різницю між прогнозами та реальними значеннями\n",
        "    errors = predictions - y\n",
        "    # Обчислюємо суму квадратів помилок та ділимо на подвоєне число зразків\n",
        "    loss = np.sum(errors ** 2) / (2 * m)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "BRbV7CuhWQPi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def gradient_descent_step(theta, X, y, learning_rate):\n",
        "    \"\"\"\n",
        "    Виконує один крок градієнтного спуску для оновлення параметрів.\n",
        "\n",
        "    Параметри:\n",
        "    theta (numpy.ndarray): Вектор параметрів розмірності (n+1, 1), де n - кількість ознак,\n",
        "                           theta[0] - зсув (вільний член), theta[1:] - ваги ознак.\n",
        "    X (numpy.ndarray): Матриця ознак розмірності (m, n+1), де m - кількість зразків,\n",
        "                       n - кількість ознак, X[:,0] містить всі значення зсуву (вільного члена).\n",
        "    y (numpy.ndarray): Вектор цільових значень розмірності (m, 1).\n",
        "    learning_rate (float): Коефіцієнт навчання.\n",
        "\n",
        "    Повертає:\n",
        "    numpy.ndarray: Оновлений вектор параметрів після виконання одного кроку градієнтного спуску.\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    # Обчислюємо прогнозовані значення за гіпотезою лінійної регресії\n",
        "    predictions = np.dot(X, theta)\n",
        "    # Обчислюємо різницю між прогнозами та реальними значеннями\n",
        "    errors = predictions - y\n",
        "    # Обчислюємо градієнт функції втрат\n",
        "    gradient = np.dot(X.T, errors) / m\n",
        "    # Оновлюємо параметри згідно з градієнтним спуском\n",
        "    theta -= learning_rate * gradient\n",
        "    return theta\n"
      ],
      "metadata": {
        "id": "4iJWombgWoQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Зчитуємо дані з CSV-файлу\n",
        "data = pd.read_csv('Housing.csv')\n",
        "\n",
        "# Переглянемо перші кілька рядків даних\n",
        "print(data.head())\n",
        "\n",
        "# Визначимо функції для гіпотези, функції втрат та одного кроку градієнтного спуску\n",
        "def linear_regression_hypothesis(theta, X):\n",
        "    return np.dot(X, theta)\n",
        "\n",
        "def compute_loss(theta, X, y):\n",
        "    m = len(y)\n",
        "    predictions = linear_regression_hypothesis(theta, X)\n",
        "    errors = predictions - y\n",
        "    loss = np.sum(errors ** 2) / (2 * m)\n",
        "    return loss\n",
        "\n",
        "def gradient_descent_step(theta, X, y, learning_rate):\n",
        "    m = len(y)\n",
        "    predictions = linear_regression_hypothesis(theta, X)\n",
        "    errors = predictions - y\n",
        "    gradient = np.dot(X.T, errors) / m\n",
        "    theta -= learning_rate * gradient\n",
        "    return theta\n",
        "\n",
        "# Підготовка даних\n",
        "X = data[['area', 'bathrooms', 'bedrooms']].values\n",
        "y = data['price'].values.reshape(-1, 1)\n",
        "\n",
        "# Нормалізація ознак\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X_norm = (X - X_mean) / X_std\n",
        "\n",
        "# Додавання стовпця з одиницями для врахування зсуву\n",
        "m = len(y)\n",
        "X_with_bias = np.column_stack([np.ones((m, 1)), X_norm])\n",
        "\n",
        "# Ініціалізація параметрів\n",
        "theta = np.zeros((X_with_bias.shape[1], 1))\n",
        "\n",
        "# Параметри градієнтного спуску\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "\n",
        "# Градієнтний спуск\n",
        "for i in range(num_iterations):\n",
        "    theta = gradient_descent_step(theta, X_with_bias, y, learning_rate)\n",
        "\n",
        "# Виведемо знайдені параметри\n",
        "print(\"Оптимальні параметри theta:\")\n",
        "print(theta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QBbbAQKW6Pz",
        "outputId": "f005fc58-cd19-498f-f6c2-bd9aea8968ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
            "0  13300000  7420         4          2        3      yes        no       no   \n",
            "1  12250000  8960         4          4        4      yes        no       no   \n",
            "2  12250000  9960         3          2        2      yes        no      yes   \n",
            "3  12215000  7500         4          2        2      yes        no      yes   \n",
            "4  11410000  7420         4          1        2      yes       yes      yes   \n",
            "\n",
            "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
            "0              no             yes        2      yes        furnished  \n",
            "1              no             yes        3       no        furnished  \n",
            "2              no              no        2      yes   semi-furnished  \n",
            "3              no             yes        3      yes        furnished  \n",
            "4              no             yes        2       no        furnished  \n",
            "Оптимальні параметри theta:\n",
            "[[4766523.46205873]\n",
            " [ 821199.26709864]\n",
            " [ 695515.99623791]\n",
            " [ 300296.28560637]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Використання аналітичного рішення\n",
        "theta_analytical = np.dot(np.dot(np.linalg.inv(np.dot(X_with_bias.T, X_with_bias)), X_with_bias.T), y)\n",
        "\n",
        "# Виведемо знайдені параметри\n",
        "print(\"Оптимальні параметри theta за допомогою аналітичного рішення:\")\n",
        "print(theta_analytical)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn9MEHvoXg6V",
        "outputId": "53b3cf1c-6982-4fb4-cd96-9fda5d64de5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оптимальні параметри theta за допомогою аналітичного рішення:\n",
            "[[4766729.24770642]\n",
            " [ 821214.14349519]\n",
            " [ 695808.52272538]\n",
            " [ 299983.57107963]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Навчання моделі лінійної регресії за допомогою бібліотеки scikit-learn\n",
        "model = LinearRegression()\n",
        "model.fit(X_with_bias, y)\n",
        "\n",
        "# Отримання параметрів моделі\n",
        "theta_sklearn = np.concatenate((model.intercept_.reshape(-1, 1), model.coef_.reshape(-1, 1)))\n",
        "\n",
        "# Виведемо параметри, знайдені за допомогою scikit-learn\n",
        "print(\"Параметри theta за допомогою scikit-learn:\")\n",
        "print(theta_sklearn)\n",
        "\n",
        "# Перетворення розмірності параметрів theta_sklearn\n",
        "theta_sklearn_reshaped = theta_sklearn[:-1].reshape(-1, 1)\n",
        "\n",
        "# Прогнозування цін за допомогою моделі scikit-learn\n",
        "predictions_sklearn = model.predict(X_with_bias)\n",
        "\n",
        "# Прогнозування цін за допомогою ручної моделі\n",
        "predictions_manual = linear_regression_hypothesis(theta_sklearn_reshaped, X_with_bias)\n",
        "\n",
        "# Порівняння результатів\n",
        "print(\"\\nПерші 5 прогнозів за допомогою scikit-learn:\")\n",
        "print(predictions_sklearn[:5])\n",
        "print(\"\\nПерші 5 прогнозів за допомогою власної реалізації:\")\n",
        "print(predictions_manual[:5])\n",
        "\n",
        "# Порівняння результатів функції втрат\n",
        "loss_sklearn = compute_loss(theta_sklearn_reshaped, X_with_bias, y)\n",
        "loss_manual = compute_loss(theta, X_with_bias, y)\n",
        "print(\"\\nСередньоквадратична помилка за допомогою scikit-learn:\", loss_sklearn)\n",
        "print(\"Середньоквадратична помилка за допомогою власної реалізації:\", loss_manual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLMX-7AiZJTU",
        "outputId": "cd8b5429-b1ba-434a-c5a5-59edbeb33bd0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Параметри theta за допомогою scikit-learn:\n",
            "[[4766729.24770642]\n",
            " [      0.        ]\n",
            " [ 821214.14349519]\n",
            " [ 695808.52272537]\n",
            " [ 299983.57107963]]\n",
            "\n",
            "Перші 5 прогнозів за допомогою scikit-learn:\n",
            "[[ 7036627.15462756]\n",
            " [10392020.79073061]\n",
            " [ 7591864.51496454]\n",
            " [ 7066928.17491437]\n",
            " [ 5650577.65683656]]\n",
            "\n",
            "Перші 5 прогнозів за допомогою власної реалізації:\n",
            "[[ 6910852.30508533]\n",
            " [10182566.90470552]\n",
            " [ 5967237.80748714]\n",
            " [ 6910852.30508533]\n",
            " [ 5274995.00527523]]\n",
            "\n",
            "Середньоквадратична помилка за допомогою scikit-learn: 1268221591524.8154\n",
            "Середньоквадратична помилка за допомогою власної реалізації: 895585103885.1149\n"
          ]
        }
      ]
    }
  ]
}